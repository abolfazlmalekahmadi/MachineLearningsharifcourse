{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Name : Abolfazl Malekahmadi\n",
    "### Student Number : 401205167\n",
    "__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.SVM for Classification:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a linearly separable case, if one of the training samples is removed, the decision boundary will remain the same. This is because the support vector machines (SVM) algorithm aims to find the maximum margin hyperplane, which is the decision boundary that is equidistant from the closest points from both classes (i.e., the support vectors). Therefore, removing one training sample that is not a support vector will not affect the position of the decision boundary.\n",
    "\n",
    "On the other hand, if we consider the logistic regression algorithm, the decision boundary will change if one of the training samples is removed. This is because logistic regression aims to find a decision boundary that separates the two classes by maximizing the likelihood of the data given the model parameters. Therefore, removing one training sample will change the likelihood function, and consequently, the position of the decision boundary. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVM with soft margin, the slack variables $ \\xi_1$ , ..., $ \\xi_n$  are introduced to allow some misclassification in the training data. The optimization problem aims to minimize the sum of the margin and the misclassification penalty, where the penalty is controlled by the hyperparameter C.\n",
    "\n",
    "The constraint $y_i(\\mathbf{w}^{\\top}(x_i)) \\geq 1-\\xi_i$ in the optimization problem implies that any misclassification of the $i$-th training instance will lead to $\\xi_i > 0$. Therefore, the sum of all non-zero slack variables $\\sum_{i=1}^n \\xi_i$ gives an upper bound on the number of misclassified instances. This is because if a training instance $i$ is misclassified, then its corresponding $\\xi_i$ will be positive, and the total sum of slack variables will increase accordingly. Therefore, the more misclassified instances, the larger the sum of slack variables.\n",
    "\n",
    "In other words, the number of misclassified instances is upper-bounded by the sum of the non-zero slack variables:\n",
    "\n",
    "$\\text { Number of Misclassified Instances } \\leq \\sum_{i=1}^n \\xi_i$\n",
    "\n",
    "Note that the upper bound may not be tight, as some slack variables may be non-zero even for correctly classified instances. However, it provides a useful measure of the quality of the trained SVM model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient C in the primal optimization of SVM with soft margin controls the trade-off between the margin maximization and the misclassification penalty. Specifically, as the value of C increases, the penalty for misclassification becomes more severe, and the model tends to fit the training data more closely. On the other hand, as C decreases, the model puts more emphasis on the margin maximization, and allows more misclassifications in the training data.\n",
    "\n",
    "When C→0, the penalty for misclassification becomes negligible, and the optimization problem reduces to the standard hard-margin SVM, which aims to find a maximum margin hyperplane that separates the two classes without any misclassification. This may result in a model that is too simple and unable to capture the complexity of the data, especially when the data is not linearly separable.\n",
    "\n",
    "When C→∞, the penalty for misclassification becomes infinitely large, and the optimization problem tries to minimize the misclassification rate at the expense of the margin maximization. This may lead to overfitting the training data, as the model becomes too complex and sensitive to the noise in the data.\n",
    "\n",
    "Therefore, the value of C should be chosen carefully to balance the trade-off between the margin maximization and the misclassification penalty, and to avoid underfitting or overfitting. This can be done by using techniques such as cross-validation to tune the hyperparameter C based on the performance of the model on the validation set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the two classes are linearly separable, both hard SVM and logistic regression can be used to learn a linear decision boundary that separates the two classes.\n",
    "\n",
    "The main difference between hard SVM and logistic regression lies in the optimization objective and the resulting decision boundary. Hard SVM aims to find the maximum margin hyperplane that separates the two classes without any misclassification, while logistic regression aims to find a decision boundary that maximizes the likelihood of the data given the model parameters.\n",
    "\n",
    "The maximum margin hyperplane found by hard SVM is defined by the support vectors, which are the training instances that are closest to the decision boundary. These support vectors determine the position and orientation of the decision boundary and are the only training instances that affect the final solution. Therefore, the decision boundary of hard SVM is more robust to outliers and noisy data, as it is determined only by a small subset of the training data.\n",
    "\n",
    "On the other hand, the decision boundary of logistic regression is defined by the weights assigned to each feature, which are learned by minimizing the negative log-likelihood of the data. The decision boundary is a linear function of the input features and can have a different orientation and position than the maximum margin hyperplane of hard SVM. In practice, the decision boundary of logistic regression can be more flexible and can capture more complex patterns in the data than the maximum margin hyperplane of hard SVM.\n",
    "\n",
    "Another significant difference is the output of the two models. Hard SVM produces binary predictions based on the sign of the decision function, while logistic regression produces probabilities that can be interpreted as the likelihood of belonging to each class. This makes logistic regression more suitable for applications where probabilistic predictions are needed, such as risk assessment and fraud detection.\n",
    "\n",
    "Overall, both hard SVM and logistic regression can be used to learn a linear decision boundary that separates the two classes when they are linearly separable. Hard SVM has the advantage of producing a robust and efficient solution that is less sensitive to noisy data, while logistic regression has the advantage of being more flexible and providing probabilistic predictions. The choice between the two models depends on the specific application and the trade-off between accuracy, interpretability, and computational efficiency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the two classes are not linearly separable, both soft SVM and logistic regression can be used to learn a decision boundary that separates the two classes. However, they differ in their approach to dealing with misclassifications and the resulting decision boundary.\n",
    "\n",
    "Soft SVM with a slack variable approach allows for some misclassifications in the training data by introducing a penalty for each misclassified instance. The degree of misclassification allowed is controlled by a hyperparameter C, which determines the trade-off between the margin maximization and the misclassification penalty. The optimization objective is to find a decision boundary that maximizes the margin while minimizing the penalty for misclassifications.\n",
    "\n",
    "Logistic regression, on the other hand, uses a probabilistic approach to deal with misclassifications. It models the probability of each instance belonging to each class using a logistic function, and the decision boundary is defined as the threshold for these probabilities. The model is trained by maximizing the log-likelihood of the data given the model parameters.\n",
    "\n",
    "When the two classes are not linearly separable, the decision boundary of soft SVM will typically be a hyperplane that allows for some misclassifications in the training data. The number of misclassifications allowed is controlled by the hyperparameter C. In contrast, the decision boundary of logistic regression will be a smooth curve that assigns a probability to each instance. The threshold for these probabilities can be adjusted to control the number of misclassifications.\n",
    "\n",
    "One advantage of soft SVM over logistic regression is that it is more robust to outliers and noisy data. Soft SVM is less likely to be influenced by outliers since it only considers support vectors that are close to the decision boundary. Logistic regression is more sensitive to outliers since it considers all instances in the training data.\n",
    "\n",
    "Another advantage of soft SVM is that it can handle nonlinear decision boundaries by using kernel functions. Kernel functions allow soft SVM to map the input data to a higher-dimensional feature space, where the classes may become separable. Logistic regression, on the other hand, is limited to linear decision boundaries.\n",
    "\n",
    "In summary, both soft SVM and logistic regression can be used to learn a decision boundary that separates two classes when they are not linearly separable. Soft SVM is more robust to outliers and can handle nonlinear decision boundaries using kernel functions. Logistic regression is more sensitive to outliers but provides a probabilistic interpretation of the predictions. The choice between the two models depends on the specific application and the trade-off between accuracy, interpretability, and computational efficiency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Composing Kernel Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to prove that $K(x, x') = cK^{(1)}(x, x')$ is a valid kernel given that $K^{(1)}$ is a valid kernel and $c > 0$. Let $K^{(1)}$ correspond to a feature map $\\phi^{(1)}$, i.e. $K^{(1)}(x, x') = \\langle \\phi^{(1)}(x), \\phi^{(1)}(x') \\rangle$. Then we have:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{z}^{\\top} \\mathbf{K} \\mathbf{z} &= \\mathbf{z}^{\\top} c \\mathbf{K}^{(1)} \\mathbf{z} \\\n",
    "&= c \\sum_{i=1}^n \\sum_{j=1}^n z_i z_j K^{(1)}(x_i, x_j) \\\n",
    "&= c \\sum_{i=1}^n \\sum_{j=1}^n z_i z_j \\langle \\phi^{(1)}(x_i), \\phi^{(1)}(x_j) \\rangle \\\n",
    "&= c \\langle \\sum_{i=1}^n z_i \\phi^{(1)}(x_i), \\sum_{j=1}^n z_j \\phi^{(1)}(x_j) \\rangle \\\n",
    "&= c \\langle \\phi(x), \\phi(x') \\rangle\n",
    "\\end{align*}\n",
    "\n",
    "where $\\phi(x) = \\sqrt{c}\\sum_{i=1}^n z_i \\phi^{(1)}(x_i)$.\n",
    "\n",
    "Since $\\mathbf{z}^{\\top} \\mathbf{K} \\mathbf{z} = c \\langle \\phi(x), \\phi(x') \\rangle \\geq 0$ for any $\\mathbf{z} \\in \\mathbb{R}^n$, we have shown that $K(x, x') = cK^{(1)}(x, x')$ is a valid kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that $K\\left(x, x^{\\prime}\\right)=K^{(1)}\\left(x, x^{\\prime}\\right)+K^{(2)}\\left(x, x^{\\prime}\\right)$ is a valid kernel, we need to show that the kernel matrix defined by this function is positive semi-definite.\n",
    "\n",
    "Let $K^{(1)}$ and $K^{(2)}$ be valid kernels. Then, by Mercer's theorem, there exist feature maps $\\phi^{(1)}$ and $\\phi^{(2)}$ such that $K^{(1)}(x, x') = \\langle \\phi^{(1)}(x), \\phi^{(1)}(x') \\rangle$ and $K^{(2)}(x, x') = \\langle \\phi^{(2)}(x), \\phi^{(2)}(x') \\rangle$. We can define a new feature map $\\phi$ as $\\phi(x) = [\\phi^{(1)}(x), \\phi^{(2)}(x)]$, which concatenates the feature maps from $K^{(1)}$ and $K^{(2)}$.\n",
    "\n",
    "Now, let $K(x,x') = K^{(1)}(x,x') + K^{(2)}(x,x') = \\langle \\phi^{(1)}(x), \\phi^{(1)}(x') \\rangle + \\langle \\phi^{(2)}(x), \\phi^{(2)}(x') \\rangle = \\langle [\\phi^{(1)}(x), \\phi^{(2)}(x)], [\\phi^{(1)}(x'), \\phi^{(2)}(x')] \\rangle = \\langle \\phi(x), \\phi(x') \\rangle$.\n",
    "\n",
    "Therefore, $K(x,x')$ can be expressed as a dot product of feature vectors under some feature space, so it is a valid kernel. Since $K^{(1)}$ and $K^{(2)}$ are positive semi-definite kernels, their sum is also positive semi-definite, so the kernel matrix defined by $K(x,x')$ is positive semi-definite."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that $K\\left(x, x^{\\prime}\\right)=K^{(1)}\\left(x, x^{\\prime}\\right) K^{(2)}\\left(x, x^{\\prime}\\right)$ is a valid kernel, we need to show that its kernel matrix $K_{i,i'} = K(x_i, x_{i'}) = K^{(1)}(x_i, x_{i'}) K^{(2)}(x_i, x_{i'})$ is positive semi-definite.\n",
    "\n",
    "Let $\\mathbf{z} \\in \\mathbb{R}^n$ be an arbitrary vector. Then, we have:\n",
    "\n",
    "\n",
    "\n",
    "We can use the property that for any $\\phi(x)$, $K(x, x') = \\phi(x)^T\\phi(x')$ to write:\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\mathbf{z}^{\\top} \\mathbf{K} \\mathbf{z} &= \\mathbf{z}^{\\top} c \\mathbf{K}^{(1)} \\mathbf{z} \\\n",
    "&= \\sum_{i, i'} z_i z_{i'} \\phi^{(1)}(x_i)^T\\phi^{(1)}(x_{i'}) \\phi^{(2)}(x_i)^T\\phi^{(2)}(x_{i'})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\\\n",
    "&= \\sum_{i, i'} z_i z_{i'} (\\phi^{(1)}(x_i)\\phi^{(2)}(x_i))^T (\\phi^{(1)}(x_{i'})\\phi^{(2)}(x_{i'})) \\\n",
    "&= \\left(\\sum_{i=1}^n z_i \\phi^{(1)}(x_i) \\phi^{(2)}(x_i)\\right)^T \\left(\\sum_{i=1}^n z_{i'} \\phi^{(1)}(x_{i'}) \\phi^{(2)}(x_{i'})\\right) \\\n",
    "&= \\left\\|\\sum_{i=1}^n z_i \\phi^{(1)}(x_i) \\phi^{(2)}(x_i)\\right\\|^2 \\geq 0\n",
    "\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, $K\\left(x, x^{\\prime}\\right)=K^{(1)}\\left(x, x^{\\prime}\\right) K^{(2)}\\left(x, x^{\\prime}\\right)$ is a valid kernel function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the given formula, we can write:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "\n",
    "\\exp(x x^{\\prime}) &= \\lim_{i \\rightarrow \\infty} \\left(1 + x x^{\\prime} + \\frac{(x x^{\\prime})^2}{2!} + \\cdots + \\frac{(x x^{\\prime})^i}{i!}\\right) \\\n",
    "&= \\lim_{i \\rightarrow \\infty} \\sum_{j=0}^{i} \\frac{(x x^{\\prime})^j}{j!}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "&= \\lim_{i \\rightarrow \\infty} \\sum_{j=0}^{i} \\frac{x^j}{j!} \\frac{x^{\\prime j}}{j!} \\\n",
    "&= \\lim_{i \\rightarrow \\infty} \\left[\\begin{matrix} \\frac{x^0}{0!} & \\frac{x^1}{1!} & \\frac{x^2}{2!} & \\cdots & \\frac{x^i}{i!} \\end{matrix}\\right] \\left[\\begin{matrix} \\frac{(x^{\\prime})^0}{0!} \\ \\frac{(x^{\\prime})^1}{1!} \\ \\frac{(x^{\\prime})^2}{2!} \\ \\vdots \\ \\frac{(x^{\\prime})^i}{i!} \\end{matrix}\\right] \\\n",
    "&= \\left[\\begin{matrix} \\frac{1}{0!}\\exp(x) \\ \\frac{x}{1!}\\exp(x) \\ \\frac{x^2}{2!}\\exp(x) \\ \\vdots \\end{matrix}\\right]^{\\top} \\left[\\begin{matrix} \\frac{1}{0!}\\exp(x^{\\prime}) \\ \\frac{x^{\\prime}}{1!}\\exp(x^{\\prime}) \\ \\frac{(x^{\\prime})^2}{2!}\\exp(x^{\\prime}) \\ \\vdots \\end{matrix}\\right]\n",
    "\\end{align*}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have expressed $\\exp(x x^{\\prime})$ as an inner product of two vectors, which is equivalent to $\\phi(x)^{\\top} \\phi(x^{\\prime})$ for some basis function $\\phi(x)$, where $\\phi(x) = [\\exp(x^0)/0!, \\exp(x^1)/1!, \\exp(x^2)/2!, \\dots]^{\\top}$.\n",
    "\n",
    "However, this basis function $\\phi(x)$ has an infinite number of terms, which makes it computationally infeasible to use in standard logistic regression. This is because computing the dot product $\\phi(x)^{\\top} \\phi(x^{\\prime})$ requires computing an infinite sum, which is impossible in practice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4.b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "K\\left(x, x^{\\prime}\\right) & =\\exp \\left(K^{(1)}\\left(x, x^{\\prime}\\right)\\right) \\\\\n",
    "& =\\exp \\left(\\phi^{(1)}(x)^{\\top} \\phi^{(1)}\\left(x^{\\prime}\\right)\\right) \\\\\n",
    "& =\\sum_{i=0}^{\\infty} \\frac{1}{i !}\\left(\\phi^{(1)}(x)^{\\top} \\phi^{(1)}\\left(x^{\\prime}\\right)\\right)^i \\\\\n",
    "& =\\sum_{i=0}^{\\infty} \\frac{1}{i !}\\left(\\sum_{j=1}^d \\phi_j^{(1)}(x) \\phi_j^{(1)}\\left(x^{\\prime}\\right)\\right)^i\n",
    "\\end{aligned}\n",
    "$$\n",
    "Let $\\phi(x)=[\\exp(\\phi_1^{(1)}(x)),\\exp(\\phi_2^{(1)}(x)),\\ldots,\\exp(\\phi_d^{(1)}(x))]^{\\top}$ be the feature map associated with $K(x,x')=\\exp\\left(\\phi^{(1)}(x)^{\\top}\\phi^{(1)}(x')\\right)$. Then we have:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K\\left(x, x^{\\prime}\\right) & =\\sum_{i=0}^{\\infty} \\frac{1}{i !}\\left(\\sum_{j=1}^d \\phi_j^{(1)}(x) \\phi_j^{(1)}\\left(x^{\\prime}\\right)\\right)^i \\\\\n",
    "& =\\sum_{i=0}^{\\infty} \\frac{1}{i !}\\left(\\phi(x)^{\\top} \\phi\\left(x^{\\prime}\\right)\\right)^i \\\\\n",
    "& =\\phi(x)^{\\top} \\phi\\left(x^{\\prime}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Therefore, $K(x,x')=\\exp(K^{(1)}(x,x'))$ is a valid kernel, as it corresponds to a matrix of dot-products under the feature map \n",
    "\n",
    "$\\phi(x)=[\\exp(\\phi_1^{(1)}(x)),\\exp(\\phi_2^{(1)}(x)),\\ldots,\\exp(\\phi_d^{(1)}(x))]^{\\top}$.$$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write the Gaussian kernel as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "K\\left(x, x^{\\prime}\\right)=\\exp \\left(\\frac{-\\left\\|x-x^{\\prime}\\right\\|_2^2}{2 \\sigma^2}\\right)=\\exp \\left(\\frac{-x^{\\top} x+x^{\\top} x^{\\prime}-x^{\\prime \\top} x^{\\prime}}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "Using the identity derived in part (a), we can write:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "K\\left(x, x^{\\prime}\\right) & =\\exp \\left(\\frac{-x^{\\top} x}{2 \\sigma^2}\\right) \\exp \\left(\\frac{x^{\\top} x^{\\prime}}{2 \\sigma^2}\\right) \\exp \\left(\\frac{-x^{\\prime \\top} x^{\\prime}}{2 \\sigma^2}\\right) \\\\\n",
    "& =\\phi(x)^{\\top} \\phi\\left(x^{\\prime}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\phi(x)=\\left[\\exp \\left(\\frac{-x_1}{\\sqrt{2} \\sigma}\\right), \\ldots, \\exp \\left(\\frac{-x_n}{\\sqrt{2} \\sigma}\\right)\\right]^{\\top}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $K^{(1)}\\left(x, x^{\\prime}\\right)=\\left\\langle\\phi(x), \\phi\\left(x^{\\prime}\\right)\\right\\rangle=\\phi(x)^{\\top} \\phi\\left(x^{\\prime}\\right)$ is a valid kernel, and $K\\left(x, x^{\\prime}\\right)=\\exp \\left(K^{(1)}\\left(x, x^{\\prime}\\right)\\right)$ is a composition of valid kernels as shown in part (b), it follows that $K\\left(x, x^{\\prime}\\right)=\\exp \\left(\\frac{-\\left|x-x^{\\prime}\\right|_2^2}{2 \\sigma^2}\\right)$ is a valid kernel.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.K-fold Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross-validation is a technique used to evaluate the performance of machine learning models. It involves splitting the data into K equal parts, or folds, and using K-1 of these folds as training data to fit the model, and the remaining fold as a validation set to test the model. This process is repeated K times, with each fold used exactly once as the validation set.\n",
    "\n",
    "The general steps for implementing K-fold cross-validation are as follows:\n",
    "\n",
    "Shuffle the data: First, shuffle the data randomly to remove any potential ordering effects.\n",
    "\n",
    "Split the data: Split the data into K equal parts, or folds.\n",
    "\n",
    "Iterate through the folds: For each of the K folds, use it as the validation set and use the remaining K-1 folds as the training set.\n",
    "\n",
    "Train the model: Fit the model using the training set.\n",
    "\n",
    "Test the model: Test the model using the validation set and record the performance metric(s) of interest.\n",
    "\n",
    "Repeat: Repeat steps 3-5 K times, with each fold used exactly once as the validation set.\n",
    "\n",
    "Aggregate the results: Once all K folds have been used as validation sets, aggregate the results of the K runs to obtain an estimate of the model's performance.\n",
    "\n",
    "By using K-fold cross-validation, we can obtain a more reliable estimate of a model's performance than if we simply used a single train-test split. Additionally, it can help us avoid overfitting by allowing us to evaluate the model's performance on multiple validation sets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Advantages and disadvantages of k-fold cross-validation relative to the validation set approach:\n",
    "\n",
    "Advantages of k-fold cross-validation over the validation set approach:\n",
    "\n",
    "        It provides a more accurate estimate of the model's performance because it uses all available data for both training and testing, whereas the validation set approach uses only a portion of the data for testing.\n",
    "        It allows for multiple evaluations of the model, which can help to reduce the variance of the estimated performance metric.\n",
    "        It reduces the risk of overfitting compared to the validation set approach, which can lead to more robust models.\n",
    "Disadvantages of k-fold cross-validation relative to the validation set approach:\n",
    "\n",
    "        It can be computationally expensive and time-consuming, especially for large datasets or complex models.\n",
    "        It may result in a higher variance in the estimated performance metric compared to the validation set approach because each fold uses a different subset of the data for validation.\n",
    "\n",
    "b) Advantages and disadvantages of k-fold cross-validation relative to LOOCV:\n",
    "\n",
    "Advantages of k-fold cross-validation over LOOCV:\n",
    "\n",
    "        It is less computationally expensive than LOOCV, especially for large datasets, because it only requires K model fits instead of N (where N is the number of data points) fits in LOOCV.\n",
    "        It can provide a less biased estimate of the model's performance than LOOCV because each fold has a larger number of training data points than the single training set used in LOOCV.\n",
    "Disadvantages of k-fold cross-validation relative to LOOCV:\n",
    "\n",
    "        It can have a higher variance in the estimated performance metric than LOOCV because each fold uses a different subset of the data for validation, whereas LOOCV uses all data points except for one for validation.\n",
    "        It may not be appropriate for datasets with highly imbalanced classes because some folds may not contain examples of rare classes, which can result in biased performance estimates. In such cases, LOOCV may be more appropriate.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo Cross Validation (MCCV) is a resampling technique used to estimate the performance of a machine learning model by repeatedly randomly splitting the data into training and testing sets. Unlike K-fold cross-validation, where the data is split into K equally sized folds, MCCV allows for random, non-overlapping splits.\n",
    "\n",
    "\n",
    "The general steps for implementing MCCV are as follows:\n",
    "\n",
    "\n",
    "1)Set the number of iterations: Determine the number of times the model will be trained and tested using random splits of the data.\n",
    "\n",
    "2)Randomly split the data: For each iteration, randomly split the data into training and testing sets. The ratio of the training to testing data can be specified based on the size of the dataset and the complexity of the model.\n",
    "\n",
    "3)Train the model: Fit the machine learning model on the training data.\n",
    "\n",
    "4)Test the model: Use the trained model to make predictions on the testing data, and record the performance metric(s) of interest.\n",
    "\n",
    "5)Repeat: Repeat steps 2-4 for the specified number of iterations.\n",
    "\n",
    "6)Aggregate the results: Once all iterations have been completed, aggregate the results to obtain an estimate of the model's performance.\n",
    "\n",
    "MCCV can provide a more robust estimate of a model's performance than a single train-test split because it allows for multiple evaluations of the model using different random splits of the data. This can help to reduce the impact of any outliers or biases in the data. Additionally, MCCV can be useful when the dataset is too large to use K-fold cross-validation, or when the data is highly imbalanced.\n",
    "\n",
    "However, MCCV can be computationally expensive, especially for large datasets or complex models, as it requires training and testing the model multiple times. Furthermore, the results of MCCV can be more variable than those obtained using K-fold cross-validation, as the random splits may not always be representative of the underlying data distribution.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCVV (Monte Carlo Cross Validation) and K-fold Cross Validation are both resampling techniques used for evaluating machine learning models. While both techniques involve splitting the data into training and testing sets and repeating the process multiple times, there are some differences between them.\n",
    "\n",
    "Advantages of MCVV over K-fold Cross Validation:\n",
    "\n",
    "MCVV can be more flexible than K-fold Cross Validation because it allows for random, non-overlapping splits of the data. This can be useful when the data is highly imbalanced or when the underlying data distribution is complex.\n",
    "MCVV can provide a more accurate estimate of the model's performance because it uses all available data for both training and testing in each iteration. In contrast, K-fold Cross Validation uses only a portion of the data for testing in each fold.\n",
    "\n",
    "\n",
    "Disadvantages of MCVV compared to K-fold Cross Validation:\n",
    "\n",
    "MCVV can be more computationally expensive than K-fold Cross Validation because it requires randomly splitting the data multiple times.\n",
    "The results of MCVV can be more variable than those obtained using K-fold Cross Validation, as the random splits may not always be representative of the underlying data distribution.\n",
    "\n",
    "\n",
    "Advantages of K-fold Cross Validation over MCVV:\n",
    "\n",
    "K-fold Cross Validation is a well-established method and is widely used in the machine learning community. Many libraries and packages have built-in functions for K-fold Cross Validation, making it easier to implement and reproduce.\n",
    "K-fold Cross Validation can be more efficient than MCVV for large datasets or complex models because it uses a fixed number of folds, whereas MCVV requires randomly splitting the data multiple times.\n",
    "\n",
    "\n",
    "Disadvantages of K-fold Cross Validation compared to MCVV:\n",
    "\n",
    "K-fold Cross Validation assumes that the data is independent and identically distributed (i.i.d), which may not always be the case. In contrast, MCVV can be more flexible and better suited for non-i.i.d. data.\n",
    "K-fold Cross Validation may not be appropriate for datasets with highly imbalanced classes, as some folds may not contain examples of rare classes, which can result in biased performance estimates. In such cases, MCVV may be more appropriate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we have seen several hyperparameters related to machine learning algorithms, including:\n",
    "\n",
    "Learning rate: A hyperparameter used in gradient-based optimization algorithms that controls the step size during optimization. Setting it too high can result in unstable convergence or overshooting the minimum, while setting it too low can result in slow convergence or getting stuck in local minima.\n",
    "\n",
    "\n",
    "Number of hidden layers: A hyperparameter used in neural networks that determines the number of layers between the input and output layers. Setting it too low can result in underfitting, while setting it too high can result in overfitting.\n",
    "\n",
    "\n",
    "Number of hidden units: A hyperparameter used in neural networks that determines the number of neurons in each hidden layer. Setting it too low can result in underfitting, while setting it too high can result in overfitting.\n",
    "\n",
    "\n",
    "Regularization strength: A hyperparameter used to balance the tradeoff between model complexity and overfitting. Setting it too high can result in underfitting, while setting it too low can result in overfitting.\n",
    "\n",
    "\n",
    "Dropout rate: A hyperparameter used in neural networks to randomly drop out units during training to prevent overfitting. Setting it too high can result in underfitting, while setting it too low can result in overfitting.\n",
    "\n",
    "\n",
    "If these hyperparameters are set inefficiently, several bad things can happen. The model can fail to converge, resulting in poor performance or even crashing. The model can overfit, meaning it performs well on the training data but poorly on new, unseen data. Alternatively, the model can underfit, meaning it does not capture the complexity of the data and performs poorly on both training and new data. Therefore, it is important to optimize hyperparameters to achieve the best performance of the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the terms \"model parameters\" and \"hyperparameters\" refer to different types of parameters that need to be set during the learning process.\n",
    "\n",
    "Model parameters are the parameters that are learned during the training process. These parameters determine the specific values that the model takes on after it has been trained. For example, in a linear regression model, the model parameters would be the coefficients of the linear equation.\n",
    "\n",
    "Hyperparameters, on the other hand, are the parameters that are set before the training process begins. These parameters control the overall behavior of the learning algorithm and affect how the model parameters are learned. Examples of hyperparameters include the learning rate, the regularization strength, and the number of hidden layers in a neural network.\n",
    "\n",
    "The main difference between hyperparameter optimization and regular training is the type of parameters that are being optimized. During regular training, the model parameters are being adjusted to fit the training data. During hyperparameter optimization, the hyperparameters are being adjusted to find the best combination of hyperparameters that results in the best performance of the model.\n",
    "\n",
    "In other words, regular training is focused on learning the model parameters that minimize the training loss, while hyperparameter optimization is focused on finding the hyperparameters that optimize the performance of the model on new, unseen data.\n",
    "\n",
    "In summary, model parameters are learned during the training process, while hyperparameters are set before training begins and control how the model parameters are learned. Hyperparameter optimization is the process of finding the best hyperparameters for a given learning algorithm to achieve optimal performance of the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporating prior knowledge and insights about the problem into the optimization method can be beneficial for finding better solutions more efficiently. Here are some ways to incorporate prior knowledge into the optimization method:\n",
    "\n",
    "Constraints: Incorporating constraints into the optimization method is one way to incorporate prior knowledge. Constraints can limit the search space for the optimization algorithm, ensuring that only solutions that meet certain criteria are considered. For example, if we know that a certain variable should always be positive, we can add a constraint to the optimization problem to enforce this.\n",
    "\n",
    "Initialization: Initializing the optimization algorithm with prior knowledge can help it to converge faster to a better solution. For example, if we know that certain variables are likely to have certain values, we can set their initial values accordingly.\n",
    "\n",
    "Objective function: The objective function used in the optimization method can be modified to incorporate prior knowledge. For example, if we know that certain variables are more important than others, we can weight them differently in the objective function.\n",
    "\n",
    "Feature engineering: Feature engineering is the process of transforming raw data into features that are more informative for the model. By incorporating domain knowledge into feature engineering, we can create features that capture important information about the problem that might not be captured by raw data alone.\n",
    "\n",
    "Bayesian optimization: Bayesian optimization is a method that incorporates prior knowledge into the optimization process. It uses a probabilistic model to guide the search for optimal hyperparameters, taking into account prior knowledge about the problem. This can help to reduce the search space and find better solutions more efficiently.\n",
    "\n",
    "Incorporating prior knowledge into the optimization method can be challenging, but it can lead to better solutions that are more efficient to find. By understanding the problem domain and the available data, we can leverage prior knowledge to improve the optimization process.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Decision Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Calculate the entropy of the target attribute (Heart Attack):\n",
    "\n",
    "Total number of patients (N) = 6\n",
    "\n",
    "\n",
    "Number of patients with Heart Attack = 4\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 2\n",
    "\n",
    "\n",
    "Entropy = - (4/6) log2(4/6) - (2/6) log2(2/6) = 0.918\n",
    "\n",
    "\n",
    "Step 2: Calculate the entropy of each attribute:\n",
    "\n",
    "Chest Pain:\n",
    "\n",
    "Chest pain = Yes:\n",
    "\n",
    "Number of patients with Heart Attack = 3\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 0\n",
    "\n",
    "\n",
    "Entropy = - (3/3) log2(3/3) - (0/3) log2(0/3) = 0\n",
    "\n",
    "\n",
    "\n",
    "Chest pain = No:\n",
    "\n",
    "Number of patients with Heart Attack = 1\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 2\n",
    "\n",
    "\n",
    "Entropy = - (1/3) log2(1/3) - (2/3) log2(2/3) = 0.918\n",
    "\n",
    "\n",
    "Information gain = Entropy(Heart Attack) - [(3/6) * Entropy(Chest Pain = Yes) + (3/6) * Entropy(Chest Pain = No)]\n",
    "\n",
    "Information gain = 0.918 - [(3/6) * 0 + (3/6) * 0.918]\n",
    "\n",
    "      Information gain = 0.459\n",
    "\n",
    "\n",
    "\n",
    "Male:\n",
    "\n",
    "Male = Yes:\n",
    "\n",
    "Number of patients with Heart Attack = 2\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 2\n",
    "\n",
    "\n",
    "Entropy = - (2/4) log2(2/4) - (2/4) log2(2/4) = 1\n",
    "\n",
    "\n",
    "\n",
    "Male = No:\n",
    "\n",
    "Number of patients with Heart Attack = 2\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 0\n",
    "\n",
    "\n",
    "Entropy = - (2/2) log2(2/2) - (0/2) log2(0/2) = 0\n",
    "\n",
    "\n",
    "Information gain = Entropy(Heart Attack) - [(4/6) * Entropy(Male = Yes) + (2/6) * Entropy(Male = No)]\n",
    "\n",
    "\n",
    "      Information gain = 0.251\n",
    "\n",
    "Smokes:\n",
    "\n",
    "Smokes = Yes:\n",
    "\n",
    "Number of patients with Heart Attack = 3\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 1\n",
    "\n",
    "\n",
    "Entropy = - (3/4) log2(3/4) - (1/4) log2(1/4) = 0.811\n",
    "\n",
    "\n",
    "Smokes = No:\n",
    "\n",
    "Number of patients with Heart Attack = 1\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 1\n",
    "\n",
    "\n",
    "Entropy = - (1/2) log2(1/2) - (1/2) log2(1/2) = 1\n",
    "\n",
    "\n",
    "\n",
    "Information gain = Entropy(Heart Attack) - [(4/6) * Entropy(Smokes = Yes) + (2/6) * Entropy(Smokes = No)]\n",
    "\n",
    "\n",
    "\n",
    "      Information gain = 0.04\n",
    "\n",
    "\n",
    "Exercises:\n",
    "\n",
    "Exercises = Yes:\n",
    "\n",
    "Number of patients with Heart Attack = 2\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 2\n",
    "\n",
    "\n",
    "Entropy = - (2/4) log2(2/4) - (2/4) log2(2/4) = 1\n",
    "\n",
    "\n",
    "Exercises = No:\n",
    "\n",
    "Number of patients with Heart Attack = 2\n",
    "\n",
    "\n",
    "Number of patients without Heart Attack = 0\n",
    "\n",
    "    \n",
    "Entropy = - (2/2) log2(2/2) - (0/2) log2(0/2) = 0\n",
    "\n",
    "    \n",
    "Information gain = Entropy(Heart Attack) - [(4/6) * Entropy(Exercises = Yes) + (2/6) * Entropy(Exercises = No)]\n",
    "\n",
    "\n",
    "      Information gain = 0.25\n",
    "\n",
    "Based on the information gain values, we can see that Chest Pain, Male, and Exercises have the same maximum information gain of 0.459 ,0.251,0.251 while smoke has the lowest information gain of 0.04. Therefore, we will choose Chest Pain as the root node for the decision tree.\n",
    "\n",
    "Step 3: Create the decision tree:\n",
    "\n",
    "\n",
    "Root node: Chest Pain\n",
    "\n",
    "\n",
    "Chest Pain = Yes:\n",
    "\n",
    "\n",
    "Prediction: Heart Attack = Yes\n",
    "\n",
    "\n",
    "Chest Pain = No:\n",
    "\n",
    "\n",
    "Sub-node: Smokes\n",
    "\n",
    "\n",
    "Smokes = Yes:\n",
    "\n",
    "\n",
    "Prediction: Heart Attack = Yes\n",
    "\n",
    "\n",
    "Smokes = No:\n",
    "\n",
    "\n",
    "Sub-node: Exercises\n",
    "\n",
    "\n",
    "Exercises = Yes:\n",
    "\n",
    "\n",
    "Prediction: Heart Attack = Yes\n",
    "\n",
    "\n",
    "Exercises = No:\n",
    "\n",
    "\n",
    "Prediction: Heart Attack = No\n",
    "\n",
    "\n",
    "Therefore, the minimal decision tree that predicts whether or not a patient is likely to have a heart attack is:\n",
    "\n",
    "                    Chest Pain\n",
    "                      /    \\\n",
    "                     /      \\\n",
    "                    /        \\\n",
    "                  Yes       No\n",
    "                  /            \\\n",
    "                 /              \\\n",
    "          Heart Attack         male\n",
    "                               /   \\\n",
    "                              /     \\\n",
    "                             /       \\\n",
    "                            Yes     No\n",
    "                            /           \\\n",
    "                           /             \\\n",
    "                      no Heart Attack   Exercises\n",
    "                                        /   \\\n",
    "                                       /     \\\n",
    "                                      /       \\\n",
    "                                     Yes     No\n",
    "                                     /           \\\n",
    "                                    /             \\\n",
    "                              no Heart Attack      Heart Attack\n",
    "\n",
    "Note that this decision tree has a depth of three and correctly predicts the heart attack outcome for all six patients in the training data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If someone has chest pain, we start at the root node of the decision tree, which is Chest Pain.\n",
    "\n",
    "If Chest Pain = Yes, we predict Heart Attack = Yes.\n",
    "\n",
    "If Chest Pain = No, we move to the sub-node male.\n",
    "\n",
    "If Smokes = Yes, we predict Heart Attack = no.\n",
    "\n",
    "If Smokes = No, we move to the sub-node Exercises.\n",
    "\n",
    "If Exercises = Yes, we predict Heart Attack = no.\n",
    "\n",
    "If Exercises = No, we predict Heart Attack = yes.\n",
    "\n",
    "Therefore, if someone has chest pain, the decision tree predicts that they are likely to have a heart attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.AdaBoost Algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that AdaBoost never chooses two identical functions in two successive steps, we will use the following two facts:\n",
    "\n",
    "At each step of the AdaBoost algorithm, the weight distribution on the training samples is updated to give more weight to the misclassified samples, and less weight to the correctly classified samples. Therefore, the distribution of the training samples changes from step to step.\n",
    "\n",
    "At each step of the AdaBoost algorithm, a new weak learner (classifier) is trained on the updated weight distribution. Since the weight distribution changes from step to step, the weak learner chosen at each step will typically be different.\n",
    "\n",
    "Given these facts, we can show that AdaBoost never chooses two identical functions in two successive steps by contradiction. Suppose that there exist two successive steps, $t$ and $t+1$, such that $h_t = h_{t+1}$. Then, at step $t$, the weight distribution would have been updated to give more weight to the misclassified samples by $h_t$, and less weight to the correctly classified samples by $h_t$. However, at step $t+1$, the weight distribution would have been updated in the same way, since $h_t = h_{t+1}$. Therefore, the weak learner chosen at step $t+1$ would have been identical to the one chosen at step $t$, which contradicts the fact that a new weak learner is trained at each step. Thus, we have shown that AdaBoost never chooses two identical functions in two successive steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that the distribution vector and the vector with components $\\left(y_i h_t\\left(x_i\\right)\\right)$ are uncorrelated, we need to show that their dot product is equal to zero. The dot product of these two vectors is:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{aligned} \\sum_{i=1}^m D_{t+1}(i) y_i h_t\\left(x_i\\right) & =\\sum_{y_i=h_t\\left(x_i\\right)} D_{t+1}(i) \\cdot y_i+\\sum_{y_i \\neq h_t\\left(x_i\\right)} D_{t+1}(i) \\cdot y_i h_t\\left(x_i\\right) \\\\ & =\\sum_{y_i=h_t\\left(x_i\\right)} D_{t+1}(i)-\\sum_{y_i \\neq h_t\\left(x_i\\right)} D_{t+1}(i) \\\\ & =\\left(\\sum_{y_i=h_t\\left(x_i\\right)} D_{t+1}(i)\\right)-\\left(\\sum_{y_i=h_t\\left(x_i\\right)} D_t(i) \\cdot e^{\\alpha_t}\\right) \\\\ & =\\left(\\sum_{y_i=h_t\\left(x_i\\right)} D_t(i) \\cdot e^{-\\alpha_t}\\right)-\\left(\\sum_{y_i=h_t\\left(x_i\\right)} D_t(i) \\cdot e^{\\alpha_t}\\right) \\\\ & =e^{-\\alpha_t}\\left(\\sum_{y_i=h_t\\left(x_i\\right)} D_t(i)\\right)-e^{\\alpha_t}\\left(\\sum_{y_i \\neq h_t\\left(x_i\\right)} D_t(i)\\right) \\\\ & =e^{-\\alpha_t} \\cdot\\left(1-e r r_t\\right)-e^{\\alpha_t} \\cdot e r r_t \\\\ & =e^{-\\alpha_t}-e^{\\alpha_t} \\cdot\\left(2 \\cdot e r r_t-1\\right)\\end{aligned}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $err_t$ is the error rate of the classifier $h_t$.\n",
    "\n",
    "Now, note that the weight update rule of the AdaBoost algorithm ensures that $err_t < \\frac{1}{2}$ for all $t$, which implies that $2\\cdot err_t - 1 < 0$ for all $t$. Therefore, we have:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e^{-\\alpha_t}> e^{\\alpha_t} \\cdot\\left(2 \\cdot e r r_t-1\\right)$$\n",
    "\n",
    "or equivalently:\n",
    "\n",
    "$$e^{-\\alpha_t}-e^{\\alpha_t} \\cdot\\left(2 \\cdot e r r_t-1\\right) > 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have shown that the dot product of the distribution vector and the vector with components $\\left(y_i h_t\\left(x_i\\right)\\right)$ is always greater than zero. Therefore, the two vectors are not uncorrelated, and the statement that their dot product is equal to zero is not true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
